{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e539ba98",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b895e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "\n",
    "from src.utils.utils import lp_error\n",
    "from src.utils.logger import Logging\n",
    "from src.utils.colors import model_color\n",
    "\n",
    "from src.nn.tanh2 import MLP2\n",
    "from src.nn.tanh import MLP\n",
    "from src.nn.bspline import KAN\n",
    "from src.nn.kan2 import KAN2\n",
    "from src.utils.utils import clear_gpu_memory\n",
    "from src.data.IBM_data_loader import prepare_training_data, visualize_tensor_datasets\n",
    "from src.data.IBM_data_loader import load_fluid_testing_dataset\n",
    "from src.models.m2_physics3 import PINNTrainer\n",
    "from src.utils.plot_losses import plot_M1_loss_history\n",
    "from src.utils.fsi_visualization import (\n",
    "    create_frames,\n",
    "    create_animations_from_existing_frames,\n",
    ")\n",
    "from src.data.IBM_data_loader import load_training_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bace01ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:src.utils.logger:./checkpoints/2025-08-18_02-24-09-051837\n"
     ]
    }
   ],
   "source": [
    "\n",
    "CHECKPOINT_PATH = \"./checkpoints\"\n",
    "logger = Logging(CHECKPOINT_PATH)\n",
    "model_dirname = logger.get_output_dir()\n",
    "\n",
    "logger.print(model_dirname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "52006a4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory cleared!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "clear_gpu_memory()\n",
    "config = {\n",
    "    \"dataset_type\": \"old\",\n",
    "    \"training_selection_method\": \"Sobol\",\n",
    "    \"input_dim\": 3,  # (x, y, z, t)\n",
    "    \"hidden_dim\": 100,\n",
    "    \"hidden_layers_dim\": 3,\n",
    "    \"fluid_density\": 1.0,\n",
    "    \"fluid_viscosity\": 0.01,\n",
    "    \"num_epochs\": 60000,\n",
    "    \"batch_size\": 128,\n",
    "    \"learning_rate\": 1e-3,\n",
    "    \"data_weight\": 2.0,\n",
    "    \"physics_weight\": 0.01,\n",
    "    \"boundary_weight\": 2.0,\n",
    "    \"fsi_weight\": 0.5,\n",
    "    \"initial_weight\": 4.0,\n",
    "    \"checkpoint_dir\": \"./checkpoints\",\n",
    "    \"resume\": None,\n",
    "    \"print_every\": 100,\n",
    "    \"save_every\": 200,\n",
    "    \"fluid_sampling_ratio\": 0.01,\n",
    "    \"interface_sampling_ratio\": 0.07,\n",
    "    \"solid_sampling_ratio\": 0.0,\n",
    "    \"left_sampling_ratio\": 0.1,\n",
    "    \"right_sampling_ratio\": 0.15,\n",
    "    \"bottom_sampling_ratio\": 0.1,\n",
    "    \"top_sampling_ratio\": 0.1,\n",
    "    \"initial_sampling_ratio\": 0.1,\n",
    "    \"device\": torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n",
    "    \"solver\": \"kan\",\n",
    "    \"model\": \"m2\",\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "76735ee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:src.utils.logger:Config:\n",
      "INFO:src.utils.logger:dataset_type: old\n",
      "INFO:src.utils.logger:training_selection_method: Sobol\n",
      "INFO:src.utils.logger:input_dim: 3\n",
      "INFO:src.utils.logger:hidden_dim: 100\n",
      "INFO:src.utils.logger:hidden_layers_dim: 3\n",
      "INFO:src.utils.logger:fluid_density: 1.0\n",
      "INFO:src.utils.logger:fluid_viscosity: 0.01\n",
      "INFO:src.utils.logger:num_epochs: 60000\n",
      "INFO:src.utils.logger:batch_size: 128\n",
      "INFO:src.utils.logger:learning_rate: 0.001\n",
      "INFO:src.utils.logger:data_weight: 2.0\n",
      "INFO:src.utils.logger:physics_weight: 0.01\n",
      "INFO:src.utils.logger:boundary_weight: 2.0\n",
      "INFO:src.utils.logger:fsi_weight: 0.5\n",
      "INFO:src.utils.logger:initial_weight: 4.0\n",
      "INFO:src.utils.logger:checkpoint_dir: ./checkpoints\n",
      "INFO:src.utils.logger:resume: None\n",
      "INFO:src.utils.logger:print_every: 100\n",
      "INFO:src.utils.logger:save_every: 200\n",
      "INFO:src.utils.logger:fluid_sampling_ratio: 0.01\n",
      "INFO:src.utils.logger:interface_sampling_ratio: 0.07\n",
      "INFO:src.utils.logger:solid_sampling_ratio: 0.0\n",
      "INFO:src.utils.logger:left_sampling_ratio: 0.1\n",
      "INFO:src.utils.logger:right_sampling_ratio: 0.15\n",
      "INFO:src.utils.logger:bottom_sampling_ratio: 0.1\n",
      "INFO:src.utils.logger:top_sampling_ratio: 0.1\n",
      "INFO:src.utils.logger:initial_sampling_ratio: 0.1\n",
      "INFO:src.utils.logger:device: cpu\n",
      "INFO:src.utils.logger:solver: kan\n",
      "INFO:src.utils.logger:model: m2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded interface tensor from ./data/training_dataset/old/interface_tensor.pt with shape torch.Size([10166, 11])\n",
      "Loaded right tensor from ./data/training_dataset/old/right_tensor.pt with shape torch.Size([1545, 8])\n",
      "Loaded fluid_points tensor from ./data/training_dataset/old/fluid_points_tensor.pt with shape torch.Size([3986, 8])\n",
      "Loaded bottom tensor from ./data/training_dataset/old/bottom_tensor.pt with shape torch.Size([1030, 8])\n",
      "Loaded left tensor from ./data/training_dataset/old/left_tensor.pt with shape torch.Size([1030, 8])\n",
      "Loaded solid tensor from ./data/training_dataset/old/solid_tensor.pt with shape torch.Size([1452, 8])\n",
      "Loaded initial tensor from ./data/training_dataset/old/initial_tensor.pt with shape torch.Size([1330, 8])\n",
      "Loaded up tensor from ./data/training_dataset/old/up_tensor.pt with shape torch.Size([1030, 8])\n",
      "Loaded fluid tensor from ./data/training_dataset/old/fluid_tensor.pt with shape torch.Size([10508, 8])\n",
      "Loaded training dataset from ./data/training_dataset/old successfully!\n"
     ]
    }
   ],
   "source": [
    "logger.print(\"Config:\")\n",
    "for key, value in config.items():\n",
    "    logger.print(f\"{key}: {value}\")\n",
    "\n",
    "training_data_path = \"./data/training_dataset/old\"\n",
    "\n",
    "training_data = load_training_dataset(training_data_path, device=config[\"device\"])\n",
    "\n",
    "if training_data is None:\n",
    "    training_data = prepare_training_data(\n",
    "        config[\"dataset_type\"],\n",
    "        fluid_sampling_ratio=config[\"fluid_sampling_ratio\"],\n",
    "        interface_sampling_ratio=config[\"interface_sampling_ratio\"],\n",
    "        solid_sampling_ratio=config[\"solid_sampling_ratio\"],\n",
    "        left_sampling_ratio=config[\"left_sampling_ratio\"],\n",
    "        right_sampling_ratio=config[\"right_sampling_ratio\"],\n",
    "        bottom_sampling_ratio=config[\"bottom_sampling_ratio\"],\n",
    "        top_sampling_ratio=config[\"top_sampling_ratio\"],\n",
    "        initial_sampling_ratio=config[\"initial_sampling_ratio\"],\n",
    "        training_selection_method=config[\"training_selection_method\"],\n",
    "        device=config[\"device\"],\n",
    "        save_dir=training_data_path,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "31c8520c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:src.utils.logger:Fluid model architecture:\n",
      "INFO:src.utils.logger:KAN(\n",
      "  (layers): ModuleList(\n",
      "    (0-3): 4 x KANLinear(\n",
      "      (base_activation): SiLU()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "INFO:src.utils.logger:KAN(\n",
      "  (layers): ModuleList(\n",
      "    (0-3): 4 x KANLinear(\n",
      "      (base_activation): SiLU()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "INFO:src.utils.logger:Number of parameters: 206000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved tensor datasets scatter plot to ./data/training_dataset/old/tensor_datasets_scatter.png\n"
     ]
    }
   ],
   "source": [
    "\n",
    "visualize_tensor_datasets(training_data, save_dir=training_data_path)\n",
    "\n",
    "fluid_network = (\n",
    "    [config[\"input_dim\"]] + [config[\"hidden_dim\"]] * config[\"hidden_layers_dim\"] + [3]\n",
    ")\n",
    "if config[\"solver\"] == \"mlp\":\n",
    "    fluid_model = MLP(network=fluid_network)\n",
    "    solid_model = MLP(network=fluid_network)\n",
    "else:\n",
    "    fluid_model = KAN(fluid_network)\n",
    "    solid_model = KAN(fluid_network)\n",
    "\n",
    "logger.print(\"Fluid model architecture:\")\n",
    "logger.print(fluid_model)\n",
    "logger.print(solid_model)\n",
    "logger.print(\n",
    "    f\"Number of parameters: {sum(p.numel() for p in fluid_model.parameters())}\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "414b2ca4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/afrahfarea/opt/anaconda3/envs/pinn-fsi-gpu/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "INFO:src.utils.logger:Epoch 0/60000, Total: 3.2e+00, Data(F&S): 1.3e-01, Physics: 3.3e-06, Boundary: 3.1e+00, FSI: 1.1e-02, Solid: 3.5e+00, Initial: 1.0e-04, LR: 1.00e-03\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 17\u001b[39m\n\u001b[32m      1\u001b[39m trainer = PINNTrainer(\n\u001b[32m      2\u001b[39m     fluid_model=fluid_model,\n\u001b[32m      3\u001b[39m     solid_model=solid_model,\n\u001b[32m   (...)\u001b[39m\u001b[32m     13\u001b[39m     model=config[\u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m     14\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m loss_history = trainer.train(\n\u001b[32m     18\u001b[39m     num_epochs=config[\u001b[33m\"\u001b[39m\u001b[33mnum_epochs\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m     19\u001b[39m     batch_size=config[\u001b[33m\"\u001b[39m\u001b[33mbatch_size\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m     20\u001b[39m     data_weight=config[\u001b[33m\"\u001b[39m\u001b[33mdata_weight\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m     21\u001b[39m     physics_weight=config[\u001b[33m\"\u001b[39m\u001b[33mphysics_weight\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m     22\u001b[39m     boundary_weight=config[\u001b[33m\"\u001b[39m\u001b[33mboundary_weight\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m     23\u001b[39m     fsi_weight=config[\u001b[33m\"\u001b[39m\u001b[33mfsi_weight\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m     24\u001b[39m     initial_weight=config[\u001b[33m\"\u001b[39m\u001b[33minitial_weight\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m     25\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/afrah/code/pinn_fsi_ibm/src/models/m2_physics2.py:157\u001b[39m, in \u001b[36mPINNTrainer.train\u001b[39m\u001b[34m(self, num_epochs, batch_size, data_weight, physics_weight, boundary_weight, fsi_weight, initial_weight)\u001b[39m\n\u001b[32m    152\u001b[39m     losses_list[domain_type] += loss \n\u001b[32m    155\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m domain_type == \u001b[33m\"\u001b[39m\u001b[33mfluid\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    156\u001b[39m     \u001b[38;5;66;03m# NS loss using PDE residuals at non interface points (fluid points)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m157\u001b[39m     [continuity, f_u, f_v] = navier_stokes_2D_IBM(\n\u001b[32m    158\u001b[39m         \u001b[38;5;28mself\u001b[39m.fluid_model, time, x, y\n\u001b[32m    159\u001b[39m     )\n\u001b[32m    161\u001b[39m     loss = physics_weight * torch.mean(\n\u001b[32m    162\u001b[39m         continuity**\u001b[32m2\u001b[39m + f_u**\u001b[32m2\u001b[39m + f_v**\u001b[32m2\u001b[39m\n\u001b[32m    163\u001b[39m     )\n\u001b[32m    165\u001b[39m     losses_list[domain_type] += loss\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/afrah/code/pinn_fsi_ibm/src/nn/pde.py:64\u001b[39m, in \u001b[36mnavier_stokes_2D_IBM\u001b[39m\u001b[34m(fluid_model, t, x, y)\u001b[39m\n\u001b[32m     60\u001b[39m \u001b[38;5;66;03m# Second Derivatives\u001b[39;00m\n\u001b[32m     61\u001b[39m u_xx = torch.autograd.grad(\n\u001b[32m     62\u001b[39m     u_x, x, grad_outputs=torch.ones_like(u_x), create_graph=\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m     63\u001b[39m )[\u001b[32m0\u001b[39m]\n\u001b[32m---> \u001b[39m\u001b[32m64\u001b[39m u_yy = torch.autograd.grad(\n\u001b[32m     65\u001b[39m     u_y, y, grad_outputs=torch.ones_like(u_y), create_graph=\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m     66\u001b[39m )[\u001b[32m0\u001b[39m]\n\u001b[32m     68\u001b[39m v_xx = torch.autograd.grad(\n\u001b[32m     69\u001b[39m     v_x, x, grad_outputs=torch.ones_like(v_x), create_graph=\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m     70\u001b[39m )[\u001b[32m0\u001b[39m]\n\u001b[32m     71\u001b[39m v_yy = torch.autograd.grad(\n\u001b[32m     72\u001b[39m     v_y, y, grad_outputs=torch.ones_like(v_y), create_graph=\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m     73\u001b[39m )[\u001b[32m0\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/anaconda3/envs/pinn-fsi-gpu/lib/python3.12/site-packages/torch/autograd/__init__.py:411\u001b[39m, in \u001b[36mgrad\u001b[39m\u001b[34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused, is_grads_batched, materialize_grads)\u001b[39m\n\u001b[32m    407\u001b[39m     result = _vmap_internals._vmap(vjp, \u001b[32m0\u001b[39m, \u001b[32m0\u001b[39m, allow_none_pass_through=\u001b[38;5;28;01mTrue\u001b[39;00m)(\n\u001b[32m    408\u001b[39m         grad_outputs_\n\u001b[32m    409\u001b[39m     )\n\u001b[32m    410\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m411\u001b[39m     result = Variable._execution_engine.run_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    412\u001b[39m         t_outputs,\n\u001b[32m    413\u001b[39m         grad_outputs_,\n\u001b[32m    414\u001b[39m         retain_graph,\n\u001b[32m    415\u001b[39m         create_graph,\n\u001b[32m    416\u001b[39m         inputs,\n\u001b[32m    417\u001b[39m         allow_unused,\n\u001b[32m    418\u001b[39m         accumulate_grad=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    419\u001b[39m     )  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    420\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m materialize_grads:\n\u001b[32m    421\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(\n\u001b[32m    422\u001b[39m         result[i] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_tensor_like(inputs[i])\n\u001b[32m    423\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(inputs))\n\u001b[32m    424\u001b[39m     ):\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "\n",
    "trainer = PINNTrainer(\n",
    "    fluid_model=fluid_model,\n",
    "    solid_model=solid_model,\n",
    "    training_data=training_data,\n",
    "    learning_rate=config[\"learning_rate\"],\n",
    "    logger=logger,\n",
    "    device=config[\"device\"],\n",
    "    fluid_density=config[\"fluid_density\"],\n",
    "    fluid_viscosity=config[\"fluid_viscosity\"],\n",
    "    print_every=config[\"print_every\"],\n",
    "    save_every=config[\"save_every\"],\n",
    "    solver=config[\"solver\"],\n",
    "    model=config[\"model\"],\n",
    ")\n",
    "\n",
    "\n",
    "loss_history = trainer.train(\n",
    "    num_epochs=config[\"num_epochs\"],\n",
    "    batch_size=config[\"batch_size\"],\n",
    "    data_weight=config[\"data_weight\"],\n",
    "    physics_weight=config[\"physics_weight\"],\n",
    "    boundary_weight=config[\"boundary_weight\"],\n",
    "    fsi_weight=config[\"fsi_weight\"],\n",
    "    initial_weight=config[\"initial_weight\"],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc4f30a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pinn-fsi-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
