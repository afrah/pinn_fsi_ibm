{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Test FSI Problem with Different Models\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ]
        }
      ],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import gc\n",
        "\n",
        "import h5py\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Import local packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "PROJECT_ROOT = os.path.abspath(os.path.join(os.getcwd(), \"../../..\"))\n",
        "\n",
        "if PROJECT_ROOT not in sys.path:\n",
        "    sys.path.insert(0, PROJECT_ROOT)\n",
        "\n",
        "from src.utils.logger import Logging\n",
        "from src.utils.utils import lp_error\n",
        "from src.utils.logger import Logging\n",
        "\n",
        "from src.utils.plot_loss import plot_loss_history"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Set various constant variables: model path, name, etc."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Create logger"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "logger = Logging(TEST_CHECKPOINT_PATH)\n",
        "model_dirname = logger.get_output_dir()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "from src.data.IBM_data_loader import generate_fluid_testing_dataset\n",
        "\n",
        "TEST_DATA_PATH = \"../../../data/IB_PINN3.mat\"\n",
        "\n",
        "\n",
        "[time_, xfa, yfa, ufa, vfa, pfa, fxfa, fyfa] = generate_fluid_testing_dataset(\n",
        "    TEST_DATA_PATH\n",
        ")\n",
        "\n",
        "\n",
        "input_ = torch.tensor(\n",
        "    np.concatenate(\n",
        "        [time_, xfa, yfa],\n",
        "        axis=1,\n",
        "    ),\n",
        "    dtype=torch.float32,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "TEST_DATA_PKL = \"../../data/IB_PINN3.mat\"\n",
        "TEST_CHECKPOINT_PATH = os.path.join(PROJECT_ROOT, \"result/fsi\")\n",
        "\n",
        "RBA = \"/home/ubuntu/afrah/code/pinn_fsi_ibm/checkpoints/fsi/2024-10-15_18-41-49-625964/model.pth\"  # \"/home/ubuntu/afrah/code/pinn_fsi_ibm/checkpoints/fsi/2024-10-15_17-36-49-818397/model.pth\"\n",
        "FIXED_WEIGHT = \"/home/ubuntu/afrah/code/pinn_fsi_ibm/checkpoints/fsi/2024-10-15_21-46-08-833958/model.pth\"  # \"/home/ubuntu/afrah/code/pinn_fsi_ibm/checkpoints/fsi/2024-10-15_17-11-45-691256/model.pth\"\n",
        "SA = \"/home/ubuntu/afrah/code/pinn_fsi_ibm/checkpoints/fsi/2024-10-15_18-42-12-444785/model.pth\"  # \"/home/ubuntu/afrah/code/pinn_fsi_ibm/checkpoints/fsi/2024-10-15_17-37-33-081291/model.pth\"\n",
        "Grad_stat = \"/home/ubuntu/afrah/code/pinn_fsi_ibm/checkpoints/fsi/2024-10-15_18-41-55-608353/model.pth\"  # \"/home/ubuntu/afrah/code/pinn_fsi_ibm/checkpoints/fsi/2024-10-15_17-37-23-782676/model.pth\"\n",
        "\n",
        "MODEL_PATH_LIST = {\n",
        "    # \"RBA\": RBA,\n",
        "    \"Fixed\": FIXED_WEIGHT,\n",
        "    # \"SA\": SA,\n",
        "    # \"grad_stat\": Grad_stat,\n",
        "}\n",
        "\n",
        "\n",
        "SOLVER_TO_MODULE = {\n",
        "    \"tanh\": \"src.nn.tanh\",\n",
        "    \"xsig\": \"src.nn.xsigmoid\",\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load the Model and Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:src.utils.logger:MODEL_PATH /home/ubuntu/afrah/code/pinn_fsi_ibm/checkpoints/fsi/2024-10-15_21-14-36-711081/model.pth\n",
            "INFO:src.utils.logger:model loaded from /home/ubuntu/afrah/code/pinn_fsi_ibm/checkpoints/fsi/2024-10-15_21-14-36-711081/model.pth\n",
            "INFO:src.utils.logger:problem: fsi\n",
            "INFO:src.utils.logger:dataset_path:  , None\n",
            "INFO:src.utils.logger:batch size:  , 100\n",
            "INFO:src.utils.logger:network:  , None\n",
            "INFO:src.utils.logger:term loss weights :  , None\n",
            "INFO:src.utils.logger:method:  , Fixed\n",
            "INFO:src.utils.logger:solver:  , xsig\n",
            "INFO:src.utils.logger:number of iterations:  , 20001\n",
            "INFO:src.utils.logger:RelL2_U%  : 82.88 \n",
            "INFO:src.utils.logger:RelL2_V%  : 112.87 \n",
            "INFO:src.utils.logger:RelL2_P%  : 123.94 \n",
            "INFO:src.utils.logger:RelL2_Fx%  : 11666.85 \n",
            "INFO:src.utils.logger:RelL2_Fx%  : 9673.82 \n",
            "INFO:src.utils.logger:Final loss left: 8.032391e-01\n",
            "INFO:src.utils.logger:Final loss right: 8.147967e-01\n",
            "INFO:src.utils.logger:Final loss bottom: 7.908438e-01\n",
            "INFO:src.utils.logger:Final loss up: 9.682003e-01\n",
            "INFO:src.utils.logger:Final loss fluid_points: 1.361910e+04\n",
            "INFO:src.utils.logger:Final loss initial: 1.001989e+05\n",
            "INFO:src.utils.logger:Final loss fluid: 1.098924e+05\n",
            "INFO:src.utils.logger:final loss sum: 2.24e+05\n",
            "INFO:src.utils.logger:******************************\n",
            "\n",
            "INFO:src.utils.logger:file directory:\n",
            "INFO:src.utils.logger:/home/ubuntu/afrah/code/pinn_fsi_ibm/src/result/fsi/2024-10-15_20-51-23-100552\n"
          ]
        }
      ],
      "source": [
        "for method, model_path in MODEL_PATH_LIST.items():\n",
        "    logger.print(f\"MODEL_PATH {model_path}\")\n",
        "    # Load the state from the saved model\n",
        "    state = torch.load(\n",
        "        model_path,\n",
        "    )\n",
        "    config = state.get(\"config\", {})\n",
        "    solver = config.get(\"solver\")\n",
        "\n",
        "    # Extract model configuration from state\n",
        "    model_activation_name = config.get(\"activation\", \"Tanh\")\n",
        "    network_fluid = config.get(\"network_fluid\")\n",
        "    network_force = config.get(\"network_force\")\n",
        "    loss_history = state.get(\"loss_history\")\n",
        "\n",
        "    data_mean = state.get(\"data_mean\").to(\"cpu\")\n",
        "    data_std = state.get(\"data_std\").to(\"cpu\")\n",
        "\n",
        "    # Dynamically import the correct module and class\n",
        "    if solver in SOLVER_TO_MODULE:\n",
        "        module = __import__(SOLVER_TO_MODULE[solver], fromlist=[\"PINNKAN\"])\n",
        "        PINNKAN = getattr(module, \"PINNKAN\")\n",
        "\n",
        "        # Initialize fluid and solid models\n",
        "        model_fluid = PINNKAN(network_fluid, model_activation_name).to(\"cpu\")\n",
        "        model_force = PINNKAN(network_force, model_activation_name).to(\"cpu\")\n",
        "\n",
        "    model_fluid.load_state_dict(state[\"model_fluid_state_dict\"])\n",
        "    model_force.load_state_dict(state[\"model_force_state_dict\"])\n",
        "    logger.print(f\"model loaded from {model_path}\")\n",
        "    logger.print(f\"problem: {config.get('problem')}\")\n",
        "    logger.print(f\"dataset_path:  , {config.get('dataset_path')}\")\n",
        "    logger.print(f\"batch size:  , {config.get('batch_size')}\")\n",
        "    logger.print(f\"network:  , {config.get('network')}\")\n",
        "    logger.print(f\"term loss weights :  , {config.get('weights')}\")\n",
        "    logger.print(f\"method:  , {config.get('weighting')}\")\n",
        "    logger.print(f\"solver:  , {config.get('solver')}\")\n",
        "    logger.print(\n",
        "        f\"number of iterations:  , {len(loss_history[next(iter(loss_history))])}\"\n",
        "    )\n",
        "\n",
        "    test_torch_data = torch.tensor(\n",
        "        np.concatenate([time_, xfa, yfa], axis=1), dtype=torch.float32\n",
        "    ).to(\"cpu\")\n",
        "    with torch.no_grad():\n",
        "        predictions1 = model_fluid.forward(test_torch_data, data_mean, data_std)\n",
        "        predictions2 = model_force.forward(test_torch_data, data_mean, data_std)\n",
        "    if predictions1.is_cuda:\n",
        "        predictions1 = predictions1.cpu()\n",
        "        predictions2 = predictions2.cpu()\n",
        "    u_pred = predictions1[:, 0:1].numpy()\n",
        "    v_pred = predictions1[:, 1:2].numpy()\n",
        "    p_pred = predictions1[:, 2:3].numpy()\n",
        "    fx_pred = predictions2[:, 0:1].numpy()\n",
        "    fy_pred = predictions2[:, 1:2].numpy()\n",
        "\n",
        "    text = \"RelL2_\"\n",
        "    # logger.print(\"\\n Relative L2 ERROR:\")\n",
        "    u_error2 = lp_error(u_pred, ufa, (text + \"U%\"), logger, 2)\n",
        "    v_error2 = lp_error(v_pred, vfa, (text + \"V%\"), logger, 2)\n",
        "    p_error2 = lp_error(p_pred, pfa, (text + \"P%\"), logger, 2)\n",
        "    fx_error2 = lp_error(fx_pred, fxfa, (text + \"Fx%\"), logger, 2)\n",
        "    fx_error2 = lp_error(fy_pred, fxfa, (text + \"Fx%\"), logger, 2)\n",
        "\n",
        "    for key in loss_history:\n",
        "        logger.print(\"Final loss %s: %e\" % (key, loss_history[key][-1]))\n",
        "\n",
        "    final_loss_sum = sum([l[-1] for l in loss_history.values()])\n",
        "    logger.print(f\"final loss sum: {final_loss_sum:.2e}\")\n",
        "\n",
        "    logger.print(\"******************************\\n\")\n",
        "\n",
        "    # Delete model and clear cache after each iteration\n",
        "    del model_fluid\n",
        "    del model_force\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()  # Force garbage collection to release memory\n",
        "\n",
        "logger.print(\"file directory:\", logger.get_output_dir())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "pytorch-2.3.1-corona-pinn",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
