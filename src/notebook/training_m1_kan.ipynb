{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e539ba98",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "89b895e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from src.utils.utils import lp_error\n",
    "from src.utils.logger import Logging\n",
    "from src.utils.colors import model_color\n",
    "\n",
    "from src.nn.tanh import MLP\n",
    "from src.nn.bspline import KAN\n",
    "from src.utils.utils import clear_gpu_memory\n",
    "from src.data.IBM_data_loader import prepare_training_data, visualize_tensor_datasets\n",
    "from src.data.IBM_data_loader import load_fluid_testing_dataset\n",
    "from src.models.m1_physics import PINNTrainer\n",
    "from src.utils.plot_losses import plot_M1_loss_history\n",
    "from src.utils.fsi_visualization import (\n",
    "    create_frames,\n",
    "    create_animations_from_existing_frames,\n",
    ")\n",
    "from src.data.IBM_data_loader import load_training_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bace01ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:src.utils.logger:./checkpoints/2025-08-18_13-51-53-682395\n"
     ]
    }
   ],
   "source": [
    "\n",
    "CHECKPOINT_PATH = \"./checkpoints\"\n",
    "logger = Logging(CHECKPOINT_PATH)\n",
    "model_dirname = logger.get_output_dir()\n",
    "\n",
    "logger.print(model_dirname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "52006a4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory cleared!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "clear_gpu_memory()\n",
    "config = {\n",
    "    \"dataset_type\": \"old\",\n",
    "    \"training_selection_method\": \"Sobol\",\n",
    "    \"input_dim\": 3,  # (x, y, z, t)\n",
    "    \"hidden_dim\": 5,\n",
    "    \"hidden_layers_dim\": 3,\n",
    "    \"fluid_density\": 1.0,\n",
    "    \"fluid_viscosity\": 0.01,\n",
    "    \"num_epochs\": 60000,\n",
    "    \"batch_size\": 128,\n",
    "    \"learning_rate\": 1e-3,\n",
    "    \"data_weight\": 2.0,\n",
    "    \"physics_weight\": 0.01,\n",
    "    \"boundary_weight\": 2.0,\n",
    "    \"fsi_weight\": 0.5,\n",
    "    \"initial_weight\": 4.0,\n",
    "    \"checkpoint_dir\": \"./checkpoints\",\n",
    "    \"resume\": None,\n",
    "    \"print_every\": 100,\n",
    "    \"save_every\": 200,\n",
    "    \"fluid_sampling_ratio\": 0.01,\n",
    "    \"interface_sampling_ratio\": 0.07,\n",
    "    \"solid_sampling_ratio\": 0.0,\n",
    "    \"left_sampling_ratio\": 0.1,\n",
    "    \"right_sampling_ratio\": 0.15,\n",
    "    \"bottom_sampling_ratio\": 0.1,\n",
    "    \"top_sampling_ratio\": 0.1,\n",
    "    \"initial_sampling_ratio\": 0.1,\n",
    "    \"device\": torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n",
    "    \"solver\": \"kan\",\n",
    "    \"model\": \"m1\",\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "76735ee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:src.utils.logger:Config:\n",
      "INFO:src.utils.logger:dataset_type: old\n",
      "INFO:src.utils.logger:training_selection_method: Sobol\n",
      "INFO:src.utils.logger:input_dim: 3\n",
      "INFO:src.utils.logger:hidden_dim: 5\n",
      "INFO:src.utils.logger:hidden_layers_dim: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:src.utils.logger:fluid_density: 1.0\n",
      "INFO:src.utils.logger:fluid_viscosity: 0.01\n",
      "INFO:src.utils.logger:num_epochs: 60000\n",
      "INFO:src.utils.logger:batch_size: 128\n",
      "INFO:src.utils.logger:learning_rate: 0.001\n",
      "INFO:src.utils.logger:data_weight: 2.0\n",
      "INFO:src.utils.logger:physics_weight: 0.01\n",
      "INFO:src.utils.logger:boundary_weight: 2.0\n",
      "INFO:src.utils.logger:fsi_weight: 0.5\n",
      "INFO:src.utils.logger:initial_weight: 4.0\n",
      "INFO:src.utils.logger:checkpoint_dir: ./checkpoints\n",
      "INFO:src.utils.logger:resume: None\n",
      "INFO:src.utils.logger:print_every: 100\n",
      "INFO:src.utils.logger:save_every: 200\n",
      "INFO:src.utils.logger:fluid_sampling_ratio: 0.01\n",
      "INFO:src.utils.logger:interface_sampling_ratio: 0.07\n",
      "INFO:src.utils.logger:solid_sampling_ratio: 0.0\n",
      "INFO:src.utils.logger:left_sampling_ratio: 0.1\n",
      "INFO:src.utils.logger:right_sampling_ratio: 0.15\n",
      "INFO:src.utils.logger:bottom_sampling_ratio: 0.1\n",
      "INFO:src.utils.logger:top_sampling_ratio: 0.1\n",
      "INFO:src.utils.logger:initial_sampling_ratio: 0.1\n",
      "INFO:src.utils.logger:device: cpu\n",
      "INFO:src.utils.logger:solver: kan\n",
      "INFO:src.utils.logger:model: m1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded interface tensor from ./data/training_dataset/old/interface_tensor.pt with shape torch.Size([10166, 11])\n",
      "Loaded right tensor from ./data/training_dataset/old/right_tensor.pt with shape torch.Size([1545, 8])\n",
      "Loaded fluid_points tensor from ./data/training_dataset/old/fluid_points_tensor.pt with shape torch.Size([3986, 8])\n",
      "Loaded bottom tensor from ./data/training_dataset/old/bottom_tensor.pt with shape torch.Size([1030, 8])\n",
      "Loaded left tensor from ./data/training_dataset/old/left_tensor.pt with shape torch.Size([1030, 8])\n",
      "Loaded solid tensor from ./data/training_dataset/old/solid_tensor.pt with shape torch.Size([1452, 8])\n",
      "Loaded initial tensor from ./data/training_dataset/old/initial_tensor.pt with shape torch.Size([1330, 8])\n",
      "Loaded up tensor from ./data/training_dataset/old/up_tensor.pt with shape torch.Size([1030, 8])\n",
      "Loaded fluid tensor from ./data/training_dataset/old/fluid_tensor.pt with shape torch.Size([10508, 8])\n",
      "Loaded training dataset from ./data/training_dataset/old successfully!\n"
     ]
    }
   ],
   "source": [
    "logger.print(\"Config:\")\n",
    "for key, value in config.items():\n",
    "    logger.print(f\"{key}: {value}\")\n",
    "\n",
    "training_data_path = \"./data/training_dataset/old\"\n",
    "\n",
    "training_data = load_training_dataset(training_data_path, device=config[\"device\"])\n",
    "\n",
    "if training_data is None:\n",
    "    training_data = prepare_training_data(\n",
    "        config[\"dataset_type\"],\n",
    "        fluid_sampling_ratio=config[\"fluid_sampling_ratio\"],\n",
    "        interface_sampling_ratio=config[\"interface_sampling_ratio\"],\n",
    "        solid_sampling_ratio=config[\"solid_sampling_ratio\"],\n",
    "        left_sampling_ratio=config[\"left_sampling_ratio\"],\n",
    "        right_sampling_ratio=config[\"right_sampling_ratio\"],\n",
    "        bottom_sampling_ratio=config[\"bottom_sampling_ratio\"],\n",
    "        top_sampling_ratio=config[\"top_sampling_ratio\"],\n",
    "        initial_sampling_ratio=config[\"initial_sampling_ratio\"],\n",
    "        training_selection_method=config[\"training_selection_method\"],\n",
    "        device=config[\"device\"],\n",
    "        save_dir=training_data_path,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "31c8520c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:src.utils.logger:Fluid model architecture:\n",
      "INFO:src.utils.logger:KAN(\n",
      "  (layers): ModuleList(\n",
      "    (0-3): 4 x KANLinear(\n",
      "      (base_activation): SiLU()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "INFO:src.utils.logger:Number of parameters: 800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved tensor datasets scatter plot to ./data/training_dataset/old/tensor_datasets_scatter.png\n"
     ]
    }
   ],
   "source": [
    "\n",
    "visualize_tensor_datasets(training_data, save_dir=training_data_path)\n",
    "\n",
    "fluid_network = (\n",
    "    [config[\"input_dim\"]] + [config[\"hidden_dim\"]] * config[\"hidden_layers_dim\"] + [3]\n",
    ")\n",
    "if config[\"solver\"] == \"mlp\":\n",
    "    fluid_model = MLP(network=fluid_network)\n",
    "else:\n",
    "    fluid_model = KAN(fluid_network)\n",
    "\n",
    "logger.print(\"Fluid model architecture:\")\n",
    "logger.print(fluid_model)\n",
    "logger.print(\n",
    "    f\"Number of parameters: {sum(p.numel() for p in fluid_model.parameters())}\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "414b2ca4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/afrahfarea/opt/anaconda3/envs/pinn-fsi-gpu/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "INFO:src.utils.logger:Epoch 0/60000, Total: 8.3e+00, Data(F): 1.3e-01, Data(S): 7.3e-02, Physics: 8.6e-06, Boundary: 3.1e+00, FSI: 5.0e+00, Initial: 2.6e-04, LR: 1.00e-03\n",
      "INFO:src.utils.logger:Epoch 100/60000, Total: 3.0e+00, Data(F): 1.5e-01, Data(S): 1.1e-01, Physics: 1.9e-05, Boundary: 2.6e+00, FSI: 8.7e-02, Initial: 5.8e-02, LR: 1.00e-03\n",
      "INFO:src.utils.logger:Final losses:\n",
      "INFO:src.utils.logger:Final left: 2.375e-01 |  Final right: 3.560e-01 |  Final bottom: 2.912e-03 |  Final up: 7.938e-01 |  Final fluid: 2.440e-03 |  Final interface: 4.696e-02 |  Final initial: 5.996e-02 |  Final total: 1.654e+00 | \n",
      "INFO:src.utils.logger:_save_checkpoint: Epoch 200 | Training checkpoint saved at ./checkpoints/2025-08-18_13-51-53-682395/model.pth\n",
      "INFO:src.utils.logger:Epoch 200/60000, Total: 1.6e+00, Data(F): 8.5e-02, Data(S): 6.8e-02, Physics: 2.5e-03, Boundary: 1.4e+00, FSI: 4.7e-02, Initial: 5.9e-02, LR: 1.00e-03\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 16\u001b[39m\n\u001b[32m      1\u001b[39m trainer = PINNTrainer(\n\u001b[32m      2\u001b[39m     fluid_model=fluid_model,\n\u001b[32m      3\u001b[39m     training_data=training_data,\n\u001b[32m   (...)\u001b[39m\u001b[32m     12\u001b[39m     model=config[\u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m     13\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m loss_history = trainer.train(\n\u001b[32m     17\u001b[39m     num_epochs=config[\u001b[33m\"\u001b[39m\u001b[33mnum_epochs\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m     18\u001b[39m     batch_size=config[\u001b[33m\"\u001b[39m\u001b[33mbatch_size\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m     19\u001b[39m     data_weight=config[\u001b[33m\"\u001b[39m\u001b[33mdata_weight\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m     20\u001b[39m     physics_weight=config[\u001b[33m\"\u001b[39m\u001b[33mphysics_weight\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m     21\u001b[39m     boundary_weight=config[\u001b[33m\"\u001b[39m\u001b[33mboundary_weight\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m     22\u001b[39m     fsi_weight=config[\u001b[33m\"\u001b[39m\u001b[33mfsi_weight\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m     23\u001b[39m     initial_weight=config[\u001b[33m\"\u001b[39m\u001b[33minitial_weight\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m     24\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/afrah/code/pinn_fsi_ibm/src/models/m1_physics.py:155\u001b[39m, in \u001b[36mPINNTrainer.train\u001b[39m\u001b[34m(self, num_epochs, batch_size, data_weight, physics_weight, boundary_weight, fsi_weight, initial_weight)\u001b[39m\n\u001b[32m    152\u001b[39m x.requires_grad_(\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    153\u001b[39m y.requires_grad_(\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m155\u001b[39m fluid_outputs = \u001b[38;5;28mself\u001b[39m.fluid_model(\n\u001b[32m    156\u001b[39m     torch.cat([time, x, y], dim=\u001b[32m1\u001b[39m).squeeze(\u001b[32m1\u001b[39m)\n\u001b[32m    157\u001b[39m )\n\u001b[32m    158\u001b[39m p = fluid_outputs[:, \u001b[32m2\u001b[39m]\n\u001b[32m    159\u001b[39m n_x = batch_tensor[:, \u001b[32m8\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/anaconda3/envs/pinn-fsi-gpu/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1509\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1510\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1511\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._call_impl(*args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/anaconda3/envs/pinn-fsi-gpu/lib/python3.12/site-packages/torch/nn/modules/module.py:1520\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1515\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1516\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1517\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1518\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1519\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1520\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(*args, **kwargs)\n\u001b[32m   1522\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1523\u001b[39m     result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/afrah/code/pinn_fsi_ibm/src/nn/bspline.py:286\u001b[39m, in \u001b[36mKAN.forward\u001b[39m\u001b[34m(self, x, update_grid)\u001b[39m\n\u001b[32m    284\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m update_grid:\n\u001b[32m    285\u001b[39m         layer.update_grid(x)\n\u001b[32m--> \u001b[39m\u001b[32m286\u001b[39m     x = layer(x)\n\u001b[32m    287\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/anaconda3/envs/pinn-fsi-gpu/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1509\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1510\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1511\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._call_impl(*args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/anaconda3/envs/pinn-fsi-gpu/lib/python3.12/site-packages/torch/nn/modules/module.py:1520\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1515\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1516\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1517\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1518\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1519\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1520\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(*args, **kwargs)\n\u001b[32m   1522\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1523\u001b[39m     result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/afrah/code/pinn_fsi_ibm/src/nn/bspline.py:167\u001b[39m, in \u001b[36mKANLinear.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    163\u001b[39m x = x.view(-\u001b[32m1\u001b[39m, \u001b[38;5;28mself\u001b[39m.in_features)\n\u001b[32m    165\u001b[39m base_output = F.linear(\u001b[38;5;28mself\u001b[39m.base_activation(x), \u001b[38;5;28mself\u001b[39m.base_weight)\n\u001b[32m    166\u001b[39m spline_output = F.linear(\n\u001b[32m--> \u001b[39m\u001b[32m167\u001b[39m     \u001b[38;5;28mself\u001b[39m.b_splines(x).view(x.size(\u001b[32m0\u001b[39m), -\u001b[32m1\u001b[39m),\n\u001b[32m    168\u001b[39m     \u001b[38;5;28mself\u001b[39m.scaled_spline_weight.view(\u001b[38;5;28mself\u001b[39m.out_features, -\u001b[32m1\u001b[39m),\n\u001b[32m    169\u001b[39m )\n\u001b[32m    170\u001b[39m output = base_output + spline_output\n\u001b[32m    172\u001b[39m output = output.view(*original_shape[:-\u001b[32m1\u001b[39m], \u001b[38;5;28mself\u001b[39m.out_features)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/afrah/code/pinn_fsi_ibm/src/nn/bspline.py:101\u001b[39m, in \u001b[36mKANLinear.b_splines\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     99\u001b[39m bases = ((x >= grid[:, :-\u001b[32m1\u001b[39m]) & (x < grid[:, \u001b[32m1\u001b[39m:])).to(x.dtype)\n\u001b[32m    100\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m1\u001b[39m, \u001b[38;5;28mself\u001b[39m.spline_order + \u001b[32m1\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m101\u001b[39m     bases = (\n\u001b[32m    102\u001b[39m         (x - grid[:, : -(k + \u001b[32m1\u001b[39m)])\n\u001b[32m    103\u001b[39m         / (grid[:, k:-\u001b[32m1\u001b[39m] - grid[:, : -(k + \u001b[32m1\u001b[39m)])\n\u001b[32m    104\u001b[39m         * bases[:, :, :-\u001b[32m1\u001b[39m]\n\u001b[32m    105\u001b[39m     ) + (\n\u001b[32m    106\u001b[39m         (grid[:, k + \u001b[32m1\u001b[39m :] - x)\n\u001b[32m    107\u001b[39m         / (grid[:, k + \u001b[32m1\u001b[39m :] - grid[:, \u001b[32m1\u001b[39m:(-k)])\n\u001b[32m    108\u001b[39m         * bases[:, :, \u001b[32m1\u001b[39m:]\n\u001b[32m    109\u001b[39m     )\n\u001b[32m    111\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m bases.size() == (\n\u001b[32m    112\u001b[39m     x.size(\u001b[32m0\u001b[39m),\n\u001b[32m    113\u001b[39m     \u001b[38;5;28mself\u001b[39m.in_features,\n\u001b[32m    114\u001b[39m     \u001b[38;5;28mself\u001b[39m.grid_size + \u001b[38;5;28mself\u001b[39m.spline_order,\n\u001b[32m    115\u001b[39m )\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m bases.contiguous()\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "\n",
    "trainer = PINNTrainer(\n",
    "    fluid_model=fluid_model,\n",
    "    training_data=training_data,\n",
    "    learning_rate=config[\"learning_rate\"],\n",
    "    logger=logger,\n",
    "    device=config[\"device\"],\n",
    "    fluid_density=config[\"fluid_density\"],\n",
    "    fluid_viscosity=config[\"fluid_viscosity\"],\n",
    "    print_every=config[\"print_every\"],\n",
    "    save_every=config[\"save_every\"],\n",
    "    solver=config[\"solver\"],\n",
    "    model=config[\"model\"],\n",
    ")\n",
    "\n",
    "\n",
    "loss_history = trainer.train(\n",
    "    num_epochs=config[\"num_epochs\"],\n",
    "    batch_size=config[\"batch_size\"],\n",
    "    data_weight=config[\"data_weight\"],\n",
    "    physics_weight=config[\"physics_weight\"],\n",
    "    boundary_weight=config[\"boundary_weight\"],\n",
    "    fsi_weight=config[\"fsi_weight\"],\n",
    "    initial_weight=config[\"initial_weight\"],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc4f30a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pinn-fsi-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
