{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Plot Training Loss History of FSI Problem\n",
        "\n",
        "We already saved the training loss history in the saved checkpoints.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ]
        }
      ],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Import local packages\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "PROJECT_ROOT = os.path.abspath(os.path.join(os.getcwd(), \"../../..\"))\n",
        "\n",
        "if PROJECT_ROOT not in sys.path:\n",
        "    sys.path.insert(0, PROJECT_ROOT)\n",
        "\n",
        "from src.utils.logger import Logging\n",
        "from src.utils.plot_loss import plot_loss_history\n",
        "from src.utils.color import model_color"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Set various constant variables: model path, name, etc. We choose the best performing models from each architecture."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create logger\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "TEST_CHECKPOINT_PATH = os.path.join(PROJECT_ROOT, \"result/fsi\")\n",
        "\n",
        "logger = Logging(TEST_CHECKPOINT_PATH)\n",
        "model_dirname = logger.get_output_dir()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "RBA = \"/home/ubuntu/afrah/code/pinn_fsi_ibm/checkpoints/fsi/2024-10-17_20-04-44-730747/model.pth\"  # \"/home/ubuntu/afrah/code/pinn_fsi_ibm/checkpoints/fsi/2024-10-15_17-36-49-818397/model.pth\"\n",
        "FIXED_WEIGHT = \"/home/ubuntu/afrah/code/pinn_fsi_ibm/checkpoints/fsi/2024-10-17_19-42-31-747885/model.pth\"  # \"/home/ubuntu/afrah/code/pinn_fsi_ibm/checkpoints/fsi/2024-10-15_17-11-45-691256/model.pth\"\n",
        "SA = \"/home/ubuntu/afrah/code/pinn_fsi_ibm/checkpoints/fsi/2024-10-17_19-47-51-266733/model.pth\"  # \"/home/ubuntu/afrah/code/pinn_fsi_ibm/checkpoints/fsi/2024-10-15_17-37-33-081291/model.pth\"\n",
        "Grad_stat = \"/home/ubuntu/afrah/code/pinn_fsi_ibm/checkpoints/fsi/2024-10-17_20-23-54-015832/model.pth\"\n",
        "\n",
        "MODEL_PATH_LIST = {\n",
        "    \"RBA\": RBA,\n",
        "    \"Fixed\": FIXED_WEIGHT,\n",
        "    \"SA\": SA,\n",
        "    \"grad_stat\": Grad_stat,\n",
        "}\n",
        "\n",
        "\n",
        "SOLVER_TO_MODULE = {\n",
        "    \"tanh\": \"src.nn.tanh\",\n",
        "    \"xsig\": \"src.nn.xsigmoid\",\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Plot Training Loss History\n",
        "\n",
        "I saved the training loss in a pickle file during training so that I can plot it later as needed.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Load Saved Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:src.utils.logger:loss: left , final loss: 7.70e-03\n",
            "INFO:src.utils.logger:loss: right , final loss: 5.68e-03\n",
            "INFO:src.utils.logger:loss: bottom , final loss: 3.35e-05\n",
            "INFO:src.utils.logger:loss: up , final loss: 1.35e-02\n",
            "INFO:src.utils.logger:loss: fluid_points , final loss: 1.38e-02\n",
            "INFO:src.utils.logger:loss: initial , final loss: 3.05e-02\n",
            "INFO:src.utils.logger:loss: fluid , final loss: 8.13e-04\n",
            "INFO:src.utils.logger:final loss sum: 7.20e-02\n",
            "INFO:src.utils.logger:problem: fsi\n",
            "INFO:src.utils.logger:dataset_path:  , None\n",
            "INFO:src.utils.logger:batch size:  , 128\n",
            "INFO:src.utils.logger:network:  , None\n",
            "INFO:src.utils.logger:term loss weights :  , None\n",
            "INFO:src.utils.logger:weighting:  , RBA\n",
            "INFO:src.utils.logger:solver:  , xsig\n",
            "INFO:src.utils.logger:number of iterations:  , 30001\n",
            "INFO:src.utils.logger:model path:\n",
            "INFO:src.utils.logger:/home/ubuntu/afrah/code/pinn_fsi_ibm/checkpoints/fsi/2024-10-17_20-04-44-730747/model.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:src.utils.logger:loss: left , final loss: 3.60e-05\n",
            "INFO:src.utils.logger:loss: right , final loss: 1.97e-05\n",
            "INFO:src.utils.logger:loss: bottom , final loss: 3.45e-06\n",
            "INFO:src.utils.logger:loss: up , final loss: 4.90e-05\n",
            "INFO:src.utils.logger:loss: fluid_points , final loss: 4.07e+00\n",
            "INFO:src.utils.logger:loss: initial , final loss: 1.73e-03\n",
            "INFO:src.utils.logger:loss: fluid , final loss: 6.02e-01\n",
            "INFO:src.utils.logger:final loss sum: 4.67e+00\n",
            "INFO:src.utils.logger:problem: fsi\n",
            "INFO:src.utils.logger:dataset_path:  , None\n",
            "INFO:src.utils.logger:batch size:  , 128\n",
            "INFO:src.utils.logger:network:  , None\n",
            "INFO:src.utils.logger:term loss weights :  , None\n",
            "INFO:src.utils.logger:weighting:  , Fixed\n",
            "INFO:src.utils.logger:solver:  , xsig\n",
            "INFO:src.utils.logger:number of iterations:  , 60001\n",
            "INFO:src.utils.logger:model path:\n",
            "INFO:src.utils.logger:/home/ubuntu/afrah/code/pinn_fsi_ibm/checkpoints/fsi/2024-10-17_19-42-31-747885/model.pth\n",
            "INFO:src.utils.logger:loss: left , final loss: 1.19e-02\n",
            "INFO:src.utils.logger:loss: right , final loss: 6.50e-03\n",
            "INFO:src.utils.logger:loss: bottom , final loss: 1.72e-04\n",
            "INFO:src.utils.logger:loss: up , final loss: 9.23e-03\n",
            "INFO:src.utils.logger:loss: fluid_points , final loss: 1.57e-02\n",
            "INFO:src.utils.logger:loss: initial , final loss: 4.13e-02\n",
            "INFO:src.utils.logger:loss: fluid , final loss: 4.14e-02\n",
            "INFO:src.utils.logger:final loss sum: 1.26e-01\n",
            "INFO:src.utils.logger:problem: fsi\n",
            "INFO:src.utils.logger:dataset_path:  , None\n",
            "INFO:src.utils.logger:batch size:  , 128\n",
            "INFO:src.utils.logger:network:  , None\n",
            "INFO:src.utils.logger:term loss weights :  , None\n",
            "INFO:src.utils.logger:weighting:  , SA\n",
            "INFO:src.utils.logger:solver:  , xsig\n",
            "INFO:src.utils.logger:number of iterations:  , 50001\n",
            "INFO:src.utils.logger:model path:\n",
            "INFO:src.utils.logger:/home/ubuntu/afrah/code/pinn_fsi_ibm/checkpoints/fsi/2024-10-17_19-47-51-266733/model.pth\n",
            "INFO:src.utils.logger:loss: left , final loss: 1.70e-02\n",
            "INFO:src.utils.logger:loss: right , final loss: 7.81e-03\n",
            "INFO:src.utils.logger:loss: bottom , final loss: 3.33e-03\n",
            "INFO:src.utils.logger:loss: up , final loss: 4.23e-01\n",
            "INFO:src.utils.logger:loss: fluid_points , final loss: 4.80e-02\n",
            "INFO:src.utils.logger:loss: initial , final loss: 1.01e-02\n",
            "INFO:src.utils.logger:loss: fluid , final loss: 2.43e+01\n",
            "INFO:src.utils.logger:final loss sum: 2.48e+01\n",
            "INFO:src.utils.logger:problem: fsi\n",
            "INFO:src.utils.logger:dataset_path:  , None\n",
            "INFO:src.utils.logger:batch size:  , 128\n",
            "INFO:src.utils.logger:network:  , None\n",
            "INFO:src.utils.logger:term loss weights :  , None\n",
            "INFO:src.utils.logger:weighting:  , grad_stat\n",
            "INFO:src.utils.logger:solver:  , xsig\n",
            "INFO:src.utils.logger:number of iterations:  , 20001\n",
            "INFO:src.utils.logger:model path:\n",
            "INFO:src.utils.logger:/home/ubuntu/afrah/code/pinn_fsi_ibm/checkpoints/fsi/2024-10-17_20-23-54-015832/model.pth\n"
          ]
        }
      ],
      "source": [
        "all_loss_history = {}\n",
        "\n",
        "for method, model_path in MODEL_PATH_LIST.items():\n",
        "    # Load the state from the saved model\n",
        "    state = torch.load(\n",
        "        model_path,\n",
        "    )\n",
        "    config = state.get(\"config\", {})\n",
        "    solver = config.get(\"solver\")\n",
        "\n",
        "    # Extract model configuration from state\n",
        "    model_activation_name = config.get(\"activation\")\n",
        "    model_architecture = config.get(\"network\")\n",
        "    loss_history = state.get(\"loss_history\")\n",
        "\n",
        "    for lkey, lvalue in loss_history.items():\n",
        "        logger.print(f\"loss: {lkey} , final loss: {lvalue[-1]:.2e}\")\n",
        "\n",
        "    final_loss_sum = sum([l[-1] for l in loss_history.values()])\n",
        "    logger.print(f\"final loss sum: {final_loss_sum:.2e}\")\n",
        "    # Dynamically import the correct module and class\n",
        "\n",
        "    logger.print(f\"problem: {config.get('problem')}\")\n",
        "    logger.print(f\"dataset_path:  , {config.get('dataset_path')}\")\n",
        "    logger.print(f\"batch size:  , {config.get('batch_size')}\")\n",
        "    logger.print(f\"network:  , {config.get('network')}\")\n",
        "    logger.print(f\"term loss weights :  , {config.get('weights')}\")\n",
        "    logger.print(f\"weighting:  , {config.get('weighting')}\")\n",
        "    logger.print(f\"solver:  , {config.get('solver')}\")\n",
        "    logger.print(\n",
        "        f\"number of iterations:  , {len(loss_history[next(iter(loss_history))])}\"\n",
        "    )\n",
        "    logger.print(\"model path:\", model_path)\n",
        "\n",
        "    all_loss_history[method] = loss_history"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Pre-process the loss data for plotting. See the Helmholtz notebook to understand the data structure.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "model='RBA', #iter=20001\n",
            "model='Fixed', #iter=40001\n",
            "model='SA', #iter=40001\n",
            "model='grad_stat', #iter=1\n",
            "Truncated model_summed_loss_dict: dict_keys(['RBA', 'Fixed', 'SA', 'grad_stat'])\n",
            "Truncated model_summed_loss_dict: 1\n"
          ]
        }
      ],
      "source": [
        "keys = all_loss_history.keys()\n",
        "values = all_loss_history.values()\n",
        "\n",
        "# Dictionary to store model and its summed loss\n",
        "model_summed_loss_dict = {}\n",
        "\n",
        "# Calculate summed loss\n",
        "# Iterate over each model, e.g., tanh and sum their losses, e.g, lbcs, phy, ...\n",
        "for model, loss_dict in zip(keys, values):\n",
        "    total_loss = np.zeros(\n",
        "        len(\n",
        "            next(iter(loss_dict.values()))\n",
        "        )  # Assume each loss history is of equal length\n",
        "    )  # Initialize total_loss with zeros\n",
        "\n",
        "    print(f\"{model=}, #iter={len(total_loss)}\")\n",
        "\n",
        "    # Sum all losses across keys for each model\n",
        "    # Exclude the physics loss for Helmholtz\n",
        "    for key in loss_dict:\n",
        "        if key not in [\"fluid\"]:\n",
        "            total_loss += np.array(loss_dict[key])\n",
        "\n",
        "    model_summed_loss_dict[model] = total_loss\n",
        "\n",
        "# Determine the minimum length across all summed losses\n",
        "min_length = min([len(x) for x in model_summed_loss_dict.values()])\n",
        "# Truncate the lists in model_summed_loss_dict to the minimum length\n",
        "for key in model_summed_loss_dict:\n",
        "    model_summed_loss_dict[key] = model_summed_loss_dict[key][0:min_length]\n",
        "\n",
        "print(\"Truncated model_summed_loss_dict:\", model_summed_loss_dict.keys())\n",
        "print(\"Truncated model_summed_loss_dict:\", len(model_summed_loss_dict.get(\"Fixed\")))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Plot Loss History"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "polyorder must be less than window_length.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[13], line 68\u001b[0m\n\u001b[1;32m      1\u001b[0m data_list \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      2\u001b[0m     {\n\u001b[1;32m      3\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m: model_summed_loss_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFixed\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;66;03m# },\u001b[39;00m\n\u001b[1;32m     65\u001b[0m ]\n\u001b[0;32m---> 68\u001b[0m \u001b[43mplot_loss_history\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m    \u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogger\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_output_dir\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mloss_history_cavity.png\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_max\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m25\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/afrah/code/pinn_fsi_ibm/src/utils/plot_loss.py:73\u001b[0m, in \u001b[0;36mplot_loss_history\u001b[0;34m(data_list, save_path, y_max)\u001b[0m\n\u001b[1;32m     71\u001b[0m smooth_alpha \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.1\u001b[39m\n\u001b[1;32m     72\u001b[0m polyorder \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m---> 73\u001b[0m smoothed_data \u001b[38;5;241m=\u001b[39m \u001b[43msmooth_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msmooth_alpha\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwindow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpolyorder\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;66;03m# Plot the original data\u001b[39;00m\n\u001b[1;32m     76\u001b[0m sns\u001b[38;5;241m.\u001b[39mlineplot(\n\u001b[1;32m     77\u001b[0m     x\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;28mlen\u001b[39m(data)),\n\u001b[1;32m     78\u001b[0m     y\u001b[38;5;241m=\u001b[39msmoothed_data,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     83\u001b[0m     alpha\u001b[38;5;241m=\u001b[39malpha,\n\u001b[1;32m     84\u001b[0m )\n",
            "File \u001b[0;32m~/afrah/code/pinn_fsi_ibm/src/utils/plot_loss.py:22\u001b[0m, in \u001b[0;36msmooth_loss\u001b[0;34m(data, alpha, window_length, polyorder)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(ema_data) \u001b[38;5;241m<\u001b[39m window_length:  \u001b[38;5;66;03m# Avoid issues with short data\u001b[39;00m\n\u001b[1;32m     21\u001b[0m     window_length \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(ema_data) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(ema_data) \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(ema_data)\n\u001b[0;32m---> 22\u001b[0m smoothed_data \u001b[38;5;241m=\u001b[39m \u001b[43msavgol_filter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43mema_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwindow_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwindow_length\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpolyorder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpolyorder\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m smoothed_data\n",
            "File \u001b[0;32m~/miniconda3/envs/pytorch-2.3.1-corona-pinn/lib/python3.9/site-packages/scipy/signal/_savitzky_golay.py:341\u001b[0m, in \u001b[0;36msavgol_filter\u001b[0;34m(x, window_length, polyorder, deriv, delta, axis, mode, cval)\u001b[0m\n\u001b[1;32m    338\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39mfloat64 \u001b[38;5;129;01mand\u001b[39;00m x\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39mfloat32:\n\u001b[1;32m    339\u001b[0m     x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat64)\n\u001b[0;32m--> 341\u001b[0m coeffs \u001b[38;5;241m=\u001b[39m \u001b[43msavgol_coeffs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwindow_length\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpolyorder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mderiv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mderiv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdelta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdelta\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minterp\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    344\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m window_length \u001b[38;5;241m>\u001b[39m x\u001b[38;5;241m.\u001b[39mshape[axis]:\n",
            "File \u001b[0;32m~/miniconda3/envs/pytorch-2.3.1-corona-pinn/lib/python3.9/site-packages/scipy/signal/_savitzky_golay.py:101\u001b[0m, in \u001b[0;36msavgol_coeffs\u001b[0;34m(window_length, polyorder, deriv, delta, pos, use)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;66;03m# An alternative method for finding the coefficients when deriv=0 is\u001b[39;00m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;66;03m#    t = np.arange(window_length)\u001b[39;00m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;66;03m#    unit = (t == pos).astype(int)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;66;03m#    pos = nL + 1\u001b[39;00m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;66;03m#    c = savgol_coeffs(window_length, M, pos=pos, use='dot')\u001b[39;00m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m polyorder \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m window_length:\n\u001b[0;32m--> 101\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpolyorder must be less than window_length.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    103\u001b[0m halflen, rem \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdivmod\u001b[39m(window_length, \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pos \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "\u001b[0;31mValueError\u001b[0m: polyorder must be less than window_length."
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1500x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "data_list = [\n",
        "    {\n",
        "        \"data\": model_summed_loss_dict[\"Fixed\"],\n",
        "        \"color\": model_color[\"tanh\"],\n",
        "        \"name\": \"Fixed\",\n",
        "        \"alpha\": 0.9,\n",
        "        \"window\": 100,\n",
        "        \"show_avg\": False,\n",
        "        \"show_lower\": False,\n",
        "    },\n",
        "    {\n",
        "        \"data\": model_summed_loss_dict[\"RBA\"],\n",
        "        \"color\": model_color[\"bspline\"],\n",
        "        \"name\": \"RBA\",\n",
        "        \"alpha\": 0.9,\n",
        "        \"window\": 100,\n",
        "        \"show_avg\": False,\n",
        "        \"show_lower\": False,\n",
        "    },\n",
        "    {\n",
        "        \"data\": model_summed_loss_dict[\"SA\"],\n",
        "        \"color\": model_color[\"param_tanh\"],\n",
        "        \"name\": \"SA\",\n",
        "        \"alpha\": 0.9,\n",
        "        \"window\": 100,\n",
        "        \"show_avg\": False,\n",
        "        \"show_lower\": False,\n",
        "    },\n",
        "    {\n",
        "        \"data\": model_summed_loss_dict[\"grad_stat\"],\n",
        "        \"color\": model_color[\"grbf\"],\n",
        "        \"name\": \"Grad_stat\",\n",
        "        \"alpha\": 0.9,\n",
        "        \"window\": 100,\n",
        "        \"show_avg\": False,\n",
        "        \"show_lower\": False,\n",
        "    },\n",
        "    # {\n",
        "    #     \"data\": model_summed_loss_dict[\"fourier\"],\n",
        "    #     \"color\": model_color[\"fourier\"],\n",
        "    #     \"name\": \"Fourier(A1)\",\n",
        "    #     \"alpha\": 0.1,\n",
        "    #     \"window\": 100,\n",
        "    #     \"show_avg\": False,\n",
        "    #     \"show_lower\": False,\n",
        "    # },\n",
        "    # {\n",
        "    #     \"data\": model_summed_loss_dict[\"chebyshev\"],\n",
        "    #     \"color\": model_color[\"chebyshev\"],\n",
        "    #     \"name\": \"Chebyshev(A2)\",\n",
        "    #     \"alpha\": 0.1,\n",
        "    #     \"window\": 100,\n",
        "    #     \"show_avg\": False,\n",
        "    #     \"show_lower\": False,\n",
        "    # },\n",
        "    # {\n",
        "    #     \"data\": model_summed_loss_dict[\"jacobi\"],\n",
        "    #     \"color\": model_color[\"jacobi\"],\n",
        "    #     \"name\": \"Jacobi(A1)\",\n",
        "    #     \"alpha\": 0.1,\n",
        "    #     \"window\": 100,\n",
        "    #     \"show_avg\": False,\n",
        "    #     \"show_lower\": False,\n",
        "    # },\n",
        "]\n",
        "\n",
        "\n",
        "plot_loss_history(\n",
        "    data_list,\n",
        "    os.path.join(logger.get_output_dir(), \"loss_history_cavity.png\"),\n",
        "    y_max=25,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "pytorch-2.3.1-corona-pinn",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
